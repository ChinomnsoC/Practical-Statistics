{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Diagnostics in Python\n",
    "\n",
    "In this notebook, I will be exploring some concepts from model diagnostics. Here, I used python to perform logistic regression to predict binary response values in sklearn. I also assessed how well my model performed using a variety of metrics (`confusion_matrix`, `precision_score`, `recall_score`, `accuracy_score`), and assessed my model fit.\n",
    "\n",
    "\n",
    "### Concepts explored\n",
    "The learning aim of this notebook is to learn how to:\n",
    "\n",
    "* Create and evaluate confusion matrices\n",
    "* Evaluate precision and recall rates\n",
    "* Analyze true positives, false positives using edge cases\n",
    "\n",
    "### Dataset description\n",
    "\n",
    "The dataset contains four variables: `admit`, `gre`, `gpa`, and `prestige`:\n",
    "\n",
    "* `admit` is a binary variable. It indicates whether or not a candidate was admitted into UCLA (admit = 1) our not (admit = 0).\n",
    "* `gre` is the GRE score. GRE stands for Graduate Record Examination.\n",
    "* `gpa` stands for Grade Point Average.\n",
    "* `prestige` is the prestige of an applicant alta mater (the school attended before applying), with 1 being the highest (highest prestige) and 4 as the lowest (not prestigious).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit  gre   gpa  prestige\n",
       "0      0  380  3.61         3\n",
       "1      1  660  3.67         3\n",
       "2      1  800  4.00         1\n",
       "3      1  640  3.19         4\n",
       "4      0  520  2.93         4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading the necessary libraries and the dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "np.random.seed(42)\n",
    "\n",
    "df = pd.read_csv('./admissions.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do:\n",
    "\n",
    "`1.` Change prestige to dummy variable columns that are added to `df`.  \n",
    "`2.` Divide my data into training and test data.  \n",
    "`3.` Create the test set as 20% of the data, and use a random state of 0. (response should be the `admit` column).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing presitige to dummy variables, creating 4 levels\n",
    "df[['level1','level2','level3','level4']] = pd.get_dummies(df['prestige'])\n",
    "\n",
    "\n",
    "#creating x and y variables as response and explanatory variables\n",
    "X = df.drop(['admit', 'prestige', 'level1'] , axis=1)\n",
    "y = df['admit']\n",
    "\n",
    "\n",
    "#dividing data into training and test data\n",
    "X_train, X_test, y_train, y_test =train_test_split(\n",
    "    X,y,test_size=0.20, random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do:\n",
    "\n",
    "`1.` Use sklearn's Logistic Regression  to fit a logistic model using `gre`, `gpa`, and 3 of the `prestige` dummy variables.\n",
    "`2.` Fit the logistic regression model without changing any of the hyperparameters.  \n",
    "`3.` As a first score, obtain the confusion matrix.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "#instantiate logistic regression model\n",
    "log_mod = LogisticRegression()\n",
    "\n",
    "#fit the model to the training data\n",
    "log_mod.fit(X_train, y_train)\n",
    "\n",
    "#create predictions using test data\n",
    "y_preds = log_mod.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[56,  0],\n",
       "       [20,  4]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_preds) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation of Confusion Matrix\n",
    "\n",
    "* The number of non-admits correctly identified as non-admits: `56`\n",
    "* The number of admits correctly identified as admits: `4`\n",
    "* The number of admits incorrectly identified as non-admits: `20`\n",
    "* The number of non-admits incorrectly identified as admits: `0`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How well did my model perform on the test data?\n",
    "To access this, I will use a variety of metrics (`precision_score`, `recall_score`, `accuracy_score`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision score: 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('precision score:', precision_score(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precision score is the probability that our learning algorithm would correctly predicted positive observations to the total predicted positive observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall score: 0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "print('recall score:', recall_score(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recall score tells us to what degree the model correctly identified the accepted students as accepted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.75\n"
     ]
    }
   ],
   "source": [
    "print('accuracy score:', accuracy_score(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy score tells us to what degree the model correctly identified cases, whether accepted or non-accepted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*NB*: **This exercise, and the dataset used, are courtesy of the Udacity Data Analyst Nanodegree programme which I am currently part of.** "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
